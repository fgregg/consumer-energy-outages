name: Download Consumer Energy Outages and Commit JSON Output

on:
  #schedule:
    #- cron: "0 * * * *"
  workflow_dispatch:

jobs:
  run_kubra_and_commit:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Run Kubra and Create JSON Output
        run: |
          output_file="data/ce_$(date +'%Y%m%d%H%M%S').json"
          wget -O "$output_file" "https://www.consumersenergy.com/arcgispublic/rest/services/CEOutageMap/MapServer/2/query?where=1%3D1&text=&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=3&outSR=4326&havingClause=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&historicMoment=&returnDistinctValues=false&resultOffset=&resultRecordCount=&returnExtentOnly=false&datumTransformation=&parameterValues=&rangeValues=&quantizationParameters=&featureEncoding=esriDefault&f=geojson"

      - name: Commit changes
        uses: EndBug/add-and-commit@v9
        with:
          message: 'update'

      - name: summarize data
        run: |
          python scripts/summarize.py data > outage_history.csv

      - name: release
        uses: WebFreak001/deploy-nightly@v2.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # automatically provided by github actions
        with:
          upload_url: https://uploads.github.com/repos/fgregg/consumer-energy-outages/releases/114337212/assets{?name,label}
          release_id: 114337212
          asset_path: ./outage_history.csv # path to archive to upload
          asset_name: outage_history.csv # name to upload the release as, use $$ to insert date (YYYYMMDD) and 6 letter commit hash
          asset_content_type: text/csv # required by GitHub API
